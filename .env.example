# ==================================
# GITHUB MODELS (Primary)
# ==================================
GITHUB_TOKEN=your_github_token_here
GITHUB_TOKEN_1=your_github_token_1
GITHUB_TOKEN_2=your_github_token_2
GITHUB_TOKEN_3=your_github_token_3

# ==================================
# EXTERNAL PROVIDERS CONFIGURATION
# Models from these providers will have a prefix (ext-*)
# ==================================

# Anthropic (Claude) Provider
ANTHROPIC_ENABLED=0
ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# OpenAI Direct Provider (separate from GitHub Models)
EXT_OPENAI_ENABLED=0
EXT_OPENAI_API_KEY=your_openai_api_key_here
# EXT_OPENAI_BASE_URL=https://api.openai.com/v1

# Azure OpenAI Provider
AZURE_OPENAI_ENABLED=0
AZURE_OPENAI_API_KEY=your_azure_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4

# Ollama (Local Models) Provider
OLLAMA_ENABLED=0
OLLAMA_BASE_URL=http://localhost:11434

# Google AI (Gemini) Provider
GOOGLE_AI_ENABLED=0
GOOGLE_API_KEY=your_google_api_key_here
# GOOGLE_BASE_URL=https://generativelanguage.googleapis.com/v1beta

# OpenRouter Provider
OPENROUTER_ENABLED=0
OPENROUTER_API_KEY=your_openrouter_api_key_here
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# ==================================
# SERVER CONFIGURATION
# ==================================
PORT=4000
RATE_LIMIT_ENABLED=1
RATE_LIMIT_PER_MINUTE=30
UPSTREAM_CONCURRENCY_ENABLED=1
UPSTREAM_MAX_CONCURRENT=8
UPSTREAM_QUEUE_MAX=100
UPSTREAM_QUEUE_TIMEOUT_MS=45000
