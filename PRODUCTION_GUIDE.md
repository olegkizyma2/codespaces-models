# üöÄ OpenAI Proxy - Production Guide

## üìã –ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è

**–ù–∞–¥—ñ–π–Ω–∏–π OpenAI-—Å—É–º—ñ—Å–Ω–∏–π –ø—Ä–æ–∫—Å—ñ –¥–ª—è GitHub Models API**
- **–ü–æ—Ä—Ç**: 4000
- **Endpoint**: `http://localhost:4000`
- **PM2 –ø—Ä–æ—Ü–µ—Å**: `openai-proxy`
- **–ê–∫—Ç–∏–≤–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π**: 30 –∑ 58 (52% success rate)

## üîß –ö–µ—Ä—É–≤–∞–Ω–Ω—è —Å–µ—Ä–≤—ñ—Å–æ–º

### –ó–∞–ø—É—Å–∫/–ø–µ—Ä–µ–∑–∞–ø—É—Å–∫
```bash
# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø—Ä–æ–∫—Å—ñ
pm2 restart openai-proxy

# –°—Ç–∞—Ç—É—Å
pm2 status

# –õ–æ–≥–∏
pm2 logs openai-proxy

# –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥
pm2 monit
```

### –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤'—è
```bash
# –ë–∞–∑–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞
curl http://localhost:4000/health

# –î–µ—Ç–∞–ª—å–Ω–∞ –≥–æ—Ç–æ–≤–Ω—ñ—Å—Ç—å
curl http://localhost:4000/ready

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
curl http://localhost:4000/v1/models
```

## üéØ PRODUCTION-READY –∑–∞–ø–∏—Ç–∏

### ‚úÖ –ù–∞–π–Ω–∞–¥—ñ–π–Ω—ñ—à—ñ –º–æ–¥–µ–ª—ñ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É

#### 1. –®–≤–∏–¥–∫—ñ —Ç–∞ —Å—Ç–∞–±—ñ–ª—å–Ω—ñ (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)
```bash
# Mistral 3B - –Ω–∞–π—à–≤–∏–¥—à–∞ (45 req/min)
curl -X POST "http://localhost:4000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "mistral-ai/ministral-3b",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello, how are you?"}
    ],
    "max_tokens": 150,
    "temperature": 0.7
  }'

# OpenAI GPT-4.1 Mini - –Ω–∞–¥—ñ–π–Ω–∞
curl -X POST "http://localhost:4000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "openai/gpt-4.1-mini",
    "messages": [
      {"role": "user", "content": "Explain quantum computing in simple terms"}
    ],
    "max_tokens": 200,
    "temperature": 0.5
  }'

# Mistral Small - –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∞ (40 req/min)
curl -X POST "http://localhost:4000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "mistral-ai/mistral-small-2503",
    "messages": [
      {"role": "user", "content": "Write a Python function to calculate fibonacci"}
    ],
    "max_tokens": 300
  }'
```

#### 2. –ü–æ—Ç—É–∂–Ω—ñ –º–æ–¥–µ–ª—ñ –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –∑–∞–≤–¥–∞–Ω—å
```bash
# Meta Llama 405B - –Ω–∞–π–ø–æ—Ç—É–∂–Ω—ñ—à–∞
curl -X POST "http://localhost:4000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "meta/meta-llama-3.1-405b-instruct",
    "messages": [
      {"role": "user", "content": "Analyze this complex business problem and provide strategic recommendations"}
    ],
    "max_tokens": 500,
    "temperature": 0.3
  }'

# Mistral Large - –¥–ª—è –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏
curl -X POST "http://localhost:4000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "mistral-ai/mistral-large-2411",
    "messages": [
      {"role": "user", "content": "Perform detailed financial analysis of the following data"}
    ],
    "max_tokens": 800
  }'
```

#### 3. –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –º–æ–¥–µ–ª—ñ
```bash
# –ü—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è - Codestral
curl -X POST "http://localhost:4000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "mistral-ai/codestral-2501",
    "messages": [
      {"role": "user", "content": "Write a REST API in Node.js with authentication"}
    ],
    "max_tokens": 1000
  }'

# –õ–æ–≥—ñ—á–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è - Phi-4 Reasoning
curl -X POST "http://localhost:4000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "microsoft/phi-4-reasoning",
    "messages": [
      {"role": "user", "content": "Solve this logic puzzle step by step"}
    ],
    "max_tokens": 400
  }'

# –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è - Vision
curl -X POST "http://localhost:4000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "meta/llama-3.2-11b-vision-instruct",
    "messages": [
      {"role": "user", "content": "Describe what you see in this image"}
    ],
    "max_tokens": 300
  }'
```

### üîÑ Streaming –∑–∞–ø–∏—Ç–∏
```bash
# Streaming –≤—ñ–¥–ø–æ–≤—ñ–¥—å
curl -X POST "http://localhost:4000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "mistral-ai/ministral-3b",
    "messages": [
      {"role": "user", "content": "Tell me a story"}
    ],
    "stream": true,
    "max_tokens": 500
  }'
```

## üìä –ü–æ–≤–Ω–∏–π —Å–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö 58 –º–æ–¥–µ–ª–µ–π

### ‚úÖ –ê–ö–¢–ò–í–ù–Ü –ú–û–î–ï–õ–Ü (30) - –≥–æ—Ç–æ–≤—ñ –¥–æ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É

#### **AI21 Labs** (2/2 –∞–∫—Ç–∏–≤–Ω—ñ)
- ‚úÖ `ai21-labs/ai21-jamba-1.5-large` - 8 req/min
- ‚úÖ `ai21-labs/ai21-jamba-1.5-mini` - 25 req/min

#### **Cohere** (2/4 –∞–∫—Ç–∏–≤–Ω—ñ)
- ‚úÖ `cohere/cohere-command-a` - 15 req/min
- ‚úÖ `cohere/cohere-command-r-08-2024` - 10 req/min
- ‚ùå `cohere/cohere-command-r-plus-08-2024` - Rate limited
- ‚ùå `cohere/cohere-embed-v3-english` - 404 Not Found
- ‚ùå `cohere/cohere-embed-v3-multilingual` - 404 Not Found

#### **Core42** (1/1 –∞–∫—Ç–∏–≤–Ω–∞)
- ‚úÖ `core42/jais-30b-chat` - 6 req/min

#### **DeepSeek** (2/3 –∞–∫—Ç–∏–≤–Ω—ñ)
- ‚ùå `deepseek/deepseek-r1` - Error
- ‚úÖ `deepseek/deepseek-r1-0528` - 1 req/min
- ‚úÖ `deepseek/deepseek-v3-0324` - 1 req/min

#### **Meta/Llama** (6/6 –∞–∫—Ç–∏–≤–Ω—ñ) üèÜ
- ‚úÖ `meta/llama-3.2-11b-vision-instruct` - 6 req/min
- ‚úÖ `meta/llama-3.2-90b-vision-instruct` - 3 req/min
- ‚úÖ `meta/llama-3.3-70b-instruct` - 4 req/min
- ‚úÖ `meta/llama-4-maverick-17b-128e-instruct-fp8` - 5 req/min
- ‚úÖ `meta/llama-4-scout-17b-16e-instruct` - 5 req/min
- ‚úÖ `meta/meta-llama-3.1-405b-instruct` - 2 req/min
- ‚úÖ `meta/meta-llama-3.1-8b-instruct` - 30 req/min

#### **Microsoft** (6/14 –∞–∫—Ç–∏–≤–Ω—ñ)
- ‚úÖ `microsoft/mai-ds-r1` - 5 req/min
- ‚ùå `microsoft/phi-3-medium-128k-instruct` - 404 Unknown model
- ‚ùå `microsoft/phi-3-medium-4k-instruct` - 404 Unknown model
- ‚ùå `microsoft/phi-3-mini-128k-instruct` - 404 Unknown model
- ‚ùå `microsoft/phi-3-mini-4k-instruct` - 404 Unknown model
- ‚ùå `microsoft/phi-3-small-128k-instruct` - 404 Unknown model
- ‚ùå `microsoft/phi-3-small-8k-instruct` - 404 Unknown model
- ‚ùå `microsoft/phi-3.5-mini-instruct` - 404 Unknown model
- ‚ùå `microsoft/phi-3.5-moe-instruct` - 404 Unknown model
- ‚ùå `microsoft/phi-3.5-vision-instruct` - 404 Unknown model
- ‚úÖ `microsoft/phi-4` - 8 req/min
- ‚úÖ `microsoft/phi-4-mini-instruct` - 22 req/min
- ‚úÖ `microsoft/phi-4-mini-reasoning` - 10 req/min
- ‚úÖ `microsoft/phi-4-multimodal-instruct` - 10 req/min
- ‚úÖ `microsoft/phi-4-reasoning` - 6 req/min

#### **Mistral AI** (6/6 –∞–∫—Ç–∏–≤–Ω—ñ) üèÜ
- ‚úÖ `mistral-ai/codestral-2501` - 8 req/min
- ‚úÖ `mistral-ai/ministral-3b` - 45 req/min üöÄ
- ‚úÖ `mistral-ai/mistral-large-2411` - 6 req/min
- ‚úÖ `mistral-ai/mistral-medium-2505` - 18 req/min
- ‚úÖ `mistral-ai/mistral-nemo` - 14 req/min
- ‚úÖ `mistral-ai/mistral-small-2503` - 40 req/min

#### **OpenAI** (2/12 –∞–∫—Ç–∏–≤–Ω—ñ)
- ‚ùå `openai/gpt-4.1` - Rate limited
- ‚úÖ `openai/gpt-4.1-mini` - 30 req/min
- ‚úÖ `openai/gpt-4.1-nano` - 45 req/min
- ‚ùå `openai/gpt-4o` - Rate limited
- ‚ùå `openai/gpt-4o-mini` - Error
- ‚ùå `openai/gpt-5` - 400 Unavailable
- ‚ùå `openai/gpt-5-chat` - 400 Unavailable
- ‚ùå `openai/gpt-5-mini` - 400 Unavailable
- ‚ùå `openai/gpt-5-nano` - 400 Unavailable
- ‚ùå `openai/o1` - 403 Forbidden
- ‚ùå `openai/o1-mini` - 403 Forbidden
- ‚ùå `openai/o1-preview` - 403 Forbidden
- ‚ùå `openai/o3` - 403 Forbidden
- ‚ùå `openai/o3-mini` - 403 Forbidden
- ‚ùå `openai/o4-mini` - 400 Unavailable
- ‚ùå `openai/text-embedding-3-large` - Wrong endpoint (use /v1/embeddings)
- ‚ùå `openai/text-embedding-3-small` - Wrong endpoint (use /v1/embeddings)

#### **xAI** (2/2 –∞–∫—Ç–∏–≤–Ω—ñ)
- ‚úÖ `xai/grok-3` - 6 req/min
- ‚úÖ `xai/grok-3-mini` - 18 req/min

## üõ°Ô∏è –ó–∞—Ö–∏—Å—Ç —Ç–∞ –Ω–∞–¥—ñ–π–Ω—ñ—Å—Ç—å

### –ê–∫—Ç–∏–≤–Ω—ñ –º–µ—Ö–∞–Ω—ñ–∑–º–∏ –∑–∞—Ö–∏—Å—Ç—É
- ‚úÖ **Rate Limiting**: 30 req/min per API key
- ‚úÖ **DDoS Protection**: 100 req/min per IP
- ‚úÖ **Circuit Breakers**: Auto-disable failed models
- ‚úÖ **Queue System**: 100 requests, 8 concurrent
- ‚úÖ **Retry Logic**: 3 attempts with exponential backoff
- ‚úÖ **Request Validation**: Max 10MB request size

### –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥
```bash
# –ú–µ—Ç—Ä–∏–∫–∏ Prometheus
curl http://localhost:4000/metrics

# –°—Ç–∞—Ç—É—Å —á–µ—Ä–≥–∏
curl http://localhost:4000/ready

# Adaptive rate limits
curl http://localhost:4000/v1/rate-limits/observed
```

## üöÄ Production Deployment

### –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
```bash
# Environment variables
export NODE_ENV=production
export PORT=4000
export UPSTREAM_MAX_CONCURRENT=8
export QUEUE_MAX_LENGTH=100
export RATE_LIMIT_PER_MINUTE=30
export RETRY_ATTEMPTS=3
```

### Load Balancing
–î–ª—è –≤–∏—Å–æ–∫–æ–≥–æ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–æ–∑–≥–æ—Ä–Ω—ñ—Ç—å –∫—ñ–ª—å–∫–∞ —ñ–Ω—Å—Ç–∞–Ω—Å—ñ–≤:
```bash
# PM2 cluster mode
pm2 start ecosystem.config.js --env production
pm2 scale openai-proxy 4  # 4 instances
```

## üìà –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

### –î–ª—è —Ä—ñ–∑–Ω–∏—Ö —Å—Ü–µ–Ω–∞—Ä—ñ—ó–≤:

**–ß–∞—Ç-–±–æ—Ç–∏ —Ç–∞ —à–≤–∏–¥–∫—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ:**
- `mistral-ai/ministral-3b` (45 req/min)
- `openai/gpt-4.1-nano` (45 req/min)

**–ë—ñ–∑–Ω–µ—Å-–∞–Ω–∞–ª—ñ—Ç–∏–∫–∞:**
- `mistral-ai/mistral-small-2503` (40 req/min)
- `meta/meta-llama-3.1-8b-instruct` (30 req/min)

**–°–∫–ª–∞–¥–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è:**
- `meta/meta-llama-3.1-405b-instruct` (2 req/min)
- `mistral-ai/mistral-large-2411` (6 req/min)

**–ü—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è:**
- `mistral-ai/codestral-2501` (8 req/min)

**–õ–æ–≥—ñ—á–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è:**
- `microsoft/phi-4-reasoning` (6 req/min)
- `deepseek/deepseek-v3-0324` (1 req/min)

## ‚ö†Ô∏è –í–∞–∂–ª–∏–≤—ñ –ø—Ä–∏–º—ñ—Ç–∫–∏

1. **Rate Limits**: –î–µ—è–∫—ñ –º–æ–¥–µ–ª—ñ –º–∞—é—Ç—å –¥–µ–Ω–Ω—ñ –ª—ñ–º—ñ—Ç–∏
2. **Embedding –º–æ–¥–µ–ª—ñ**: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ `/v1/embeddings` endpoint
3. **o1/o3 —Å–µ—Ä—ñ—è**: –ü–æ—Ç—Ä–µ–±—É—î —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏—Ö –¥–æ–∑–≤–æ–ª—ñ–≤
4. **GPT-5**: –©–µ –Ω–µ –≤–∏–ø—É—â–µ–Ω—ñ –ø—É–±–ª—ñ—á–Ω–æ
5. **Phi-3.x**: –¢–∏–º—á–∞—Å–æ–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ (404 errors)

## üîß Troubleshooting

### –ß–∞—Å—Ç—ñ –ø–æ–º–∏–ª–∫–∏:
```bash
# 404 Unknown model - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∞–∫—Ç–∏–≤–Ω—ñ –º–æ–¥–µ–ª—ñ
# 429 Rate limit - –∑–º–µ–Ω—à—ñ—Ç—å —á–∞—Å—Ç–æ—Ç—É –∑–∞–ø–∏—Ç—ñ–≤
# 403 Forbidden - –º–æ–¥–µ–ª—å –ø–æ—Ç—Ä–µ–±—É—î —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏—Ö –¥–æ–∑–≤–æ–ª—ñ–≤
# 500 Circuit breaker - –º–æ–¥–µ–ª—å —Ç–∏–º—á–∞—Å–æ–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
```

### –õ–æ–≥–∏:
```bash
# –†–µ–∞–ª—å–Ω–∏–π —á–∞—Å
pm2 logs openai-proxy --lines 100

# –§–∞–π–ª–∏ –ª–æ–≥—ñ–≤
tail -f logs/openai-proxy-out.log
tail -f logs/openai-proxy-error.log
```

---

**‚úÖ –ü—Ä–æ–∫—Å—ñ –≥–æ—Ç–æ–≤–∏–π –¥–æ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É –∑ 30 –Ω–∞–¥—ñ–π–Ω–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏!**
